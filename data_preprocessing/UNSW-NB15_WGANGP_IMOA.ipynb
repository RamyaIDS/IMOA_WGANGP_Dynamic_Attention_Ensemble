{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223de891-1682-4c9e-9f4b-72e9d56ca04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b07b49-f1f5-48c4-bce6-e483444d3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Train and Test dataset for data pre-processing\n",
    "train = pd.read_csv(\"UNSW_NB15_training-set.csv\")\n",
    "test=pd.read_csv(\"UNSW_NB15_testing-set.csv\")\n",
    "data = pd.concat([train, test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1363a9a4-1d38-42e6-8bef-9aec0403e0f1",
   "metadata": {},
   "source": [
    "##### Sample Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88719513-c5a6-494e-aeec-1f119b1a738e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
       "0            1  0.000011   udp       -   INT      2      0     496       0   \n",
       "1            2  0.000008   udp       -   INT      2      0    1762       0   \n",
       "2            3  0.000005   udp       -   INT      2      0    1068       0   \n",
       "3            4  0.000006   udp       -   INT      2      0     900       0   \n",
       "4            5  0.000010   udp       -   INT      2      0    2126       0   \n",
       "...        ...       ...   ...     ...   ...    ...    ...     ...     ...   \n",
       "175336  175337  0.000009   udp     dns   INT      2      0     114       0   \n",
       "175337  175338  0.505762   tcp       -   FIN     10      8     620     354   \n",
       "175338  175339  0.000009   udp     dns   INT      2      0     114       0   \n",
       "175339  175340  0.000009   udp     dns   INT      2      0     114       0   \n",
       "175340  175341  0.000009   udp     dns   INT      2      0     114       0   \n",
       "\n",
       "                 rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "0        90909.090200  ...                 1               2             0   \n",
       "1       125000.000300  ...                 1               2             0   \n",
       "2       200000.005100  ...                 1               3             0   \n",
       "3       166666.660800  ...                 1               3             0   \n",
       "4       100000.002500  ...                 1               3             0   \n",
       "...               ...  ...               ...             ...           ...   \n",
       "175336  111111.107200  ...                13              24             0   \n",
       "175337      33.612649  ...                 1               2             0   \n",
       "175338  111111.107200  ...                 3              13             0   \n",
       "175339  111111.107200  ...                14              30             0   \n",
       "175340  111111.107200  ...                16              30             0   \n",
       "\n",
       "        ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
       "0                0                 0           1           2                0   \n",
       "1                0                 0           1           2                0   \n",
       "2                0                 0           1           3                0   \n",
       "3                0                 0           2           3                0   \n",
       "4                0                 0           2           3                0   \n",
       "...            ...               ...         ...         ...              ...   \n",
       "175336           0                 0          24          24                0   \n",
       "175337           0                 0           1           1                0   \n",
       "175338           0                 0           3          12                0   \n",
       "175339           0                 0          30          30                0   \n",
       "175340           0                 0          30          30                0   \n",
       "\n",
       "        attack_cat  label  \n",
       "0           Normal      0  \n",
       "1           Normal      0  \n",
       "2           Normal      0  \n",
       "3           Normal      0  \n",
       "4           Normal      0  \n",
       "...            ...    ...  \n",
       "175336     Generic      1  \n",
       "175337   Shellcode      1  \n",
       "175338     Generic      1  \n",
       "175339     Generic      1  \n",
       "175340     Generic      1  \n",
       "\n",
       "[257673 rows x 45 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887b841f-c9a8-41ff-8f1b-c55e116e6558",
   "metadata": {},
   "source": [
    "##### Number of Rows and Columns of Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c798cbb0-9181-4297-9b43-07d4c3a2999c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257673, 45)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6e76ca-506d-4e31-a693-82ebc59186e3",
   "metadata": {},
   "source": [
    "##### Numerical Features of UNSW-NB15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39df4e49-051c-48b7-954f-539ff52e7275",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'dur',\n",
       " 'spkts',\n",
       " 'dpkts',\n",
       " 'sbytes',\n",
       " 'dbytes',\n",
       " 'rate',\n",
       " 'sttl',\n",
       " 'dttl',\n",
       " 'sload',\n",
       " 'dload',\n",
       " 'sloss',\n",
       " 'dloss',\n",
       " 'sinpkt',\n",
       " 'dinpkt',\n",
       " 'sjit',\n",
       " 'djit',\n",
       " 'swin',\n",
       " 'stcpb',\n",
       " 'dtcpb',\n",
       " 'dwin',\n",
       " 'tcprtt',\n",
       " 'synack',\n",
       " 'ackdat',\n",
       " 'smean',\n",
       " 'dmean',\n",
       " 'trans_depth',\n",
       " 'response_body_len',\n",
       " 'ct_srv_src',\n",
       " 'ct_state_ttl',\n",
       " 'ct_dst_ltm',\n",
       " 'ct_src_dport_ltm',\n",
       " 'ct_dst_sport_ltm',\n",
       " 'ct_dst_src_ltm',\n",
       " 'is_ftp_login',\n",
       " 'ct_ftp_cmd',\n",
       " 'ct_flw_http_mthd',\n",
       " 'ct_src_ltm',\n",
       " 'ct_srv_dst',\n",
       " 'is_sm_ips_ports',\n",
       " 'label']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features = data.select_dtypes(include='number').columns.tolist()\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64ff3600-d318-42a2-ab0f-1462469f5db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of numerical features 41\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of numerical features\", len(numerical_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a417b-00d1-48e3-b7e8-d6f9884634d7",
   "metadata": {},
   "source": [
    "##### Categorical Features of UNSW-NB15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c5072f-5eab-4270-be26-707d53c91fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proto', 'service', 'state', 'attack_cat']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = data.select_dtypes(exclude='number').columns.tolist()\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2617fd-310b-4b16-8a88-16442ba6985f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of categorical features 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of categorical features\",len(categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ed3fef-547f-4ac0-873c-08852a028891",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 257673 entries, 0 to 175340\n",
      "Data columns (total 45 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   id                 257673 non-null  int64  \n",
      " 1   dur                257673 non-null  float64\n",
      " 2   proto              257673 non-null  object \n",
      " 3   service            257673 non-null  object \n",
      " 4   state              257673 non-null  object \n",
      " 5   spkts              257673 non-null  int64  \n",
      " 6   dpkts              257673 non-null  int64  \n",
      " 7   sbytes             257673 non-null  int64  \n",
      " 8   dbytes             257673 non-null  int64  \n",
      " 9   rate               257673 non-null  float64\n",
      " 10  sttl               257673 non-null  int64  \n",
      " 11  dttl               257673 non-null  int64  \n",
      " 12  sload              257673 non-null  float64\n",
      " 13  dload              257673 non-null  float64\n",
      " 14  sloss              257673 non-null  int64  \n",
      " 15  dloss              257673 non-null  int64  \n",
      " 16  sinpkt             257673 non-null  float64\n",
      " 17  dinpkt             257673 non-null  float64\n",
      " 18  sjit               257673 non-null  float64\n",
      " 19  djit               257673 non-null  float64\n",
      " 20  swin               257673 non-null  int64  \n",
      " 21  stcpb              257673 non-null  int64  \n",
      " 22  dtcpb              257673 non-null  int64  \n",
      " 23  dwin               257673 non-null  int64  \n",
      " 24  tcprtt             257673 non-null  float64\n",
      " 25  synack             257673 non-null  float64\n",
      " 26  ackdat             257673 non-null  float64\n",
      " 27  smean              257673 non-null  int64  \n",
      " 28  dmean              257673 non-null  int64  \n",
      " 29  trans_depth        257673 non-null  int64  \n",
      " 30  response_body_len  257673 non-null  int64  \n",
      " 31  ct_srv_src         257673 non-null  int64  \n",
      " 32  ct_state_ttl       257673 non-null  int64  \n",
      " 33  ct_dst_ltm         257673 non-null  int64  \n",
      " 34  ct_src_dport_ltm   257673 non-null  int64  \n",
      " 35  ct_dst_sport_ltm   257673 non-null  int64  \n",
      " 36  ct_dst_src_ltm     257673 non-null  int64  \n",
      " 37  is_ftp_login       257673 non-null  int64  \n",
      " 38  ct_ftp_cmd         257673 non-null  int64  \n",
      " 39  ct_flw_http_mthd   257673 non-null  int64  \n",
      " 40  ct_src_ltm         257673 non-null  int64  \n",
      " 41  ct_srv_dst         257673 non-null  int64  \n",
      " 42  is_sm_ips_ports    257673 non-null  int64  \n",
      " 43  attack_cat         257673 non-null  object \n",
      " 44  label              257673 non-null  int64  \n",
      "dtypes: float64(11), int64(30), object(4)\n",
      "memory usage: 90.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e20834f-3a0f-405b-90e2-c8e5acdfc5c2",
   "metadata": {},
   "source": [
    "##### It is clear that we dont need the id, so we may drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e898342-6800-4225-a865-511e8fbe404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7082615e-9c3c-44b7-80ea-5028225e4a99",
   "metadata": {},
   "source": [
    "##### Check for any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d26a3f9-185c-411b-adb5-b438d1f97a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eada43-9b83-4fdf-9acb-cf626cc412d4",
   "metadata": {},
   "source": [
    "##### We can't deal with categorical columns having value '-'.\n",
    "##### So Replace it with 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4565b3fe-f042-4144-8a70-818194d7ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = train.select_dtypes(include=[\"object\"]).columns\n",
    "data[categorical_cols] = data[categorical_cols].replace('-', \"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6056d4b7-a874-444c-8d71-7bd94226185e",
   "metadata": {},
   "source": [
    "##### Different services from which the network traffic has been measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8a93ccc-f031-4b24-a301-2d61b8635d7a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None        141321\n",
       "dns          68661\n",
       "http         27011\n",
       "smtp          6909\n",
       "ftp-data      5391\n",
       "ftp           4980\n",
       "pop3          1528\n",
       "ssh           1506\n",
       "dhcp           120\n",
       "snmp           109\n",
       "ssl             86\n",
       "irc             30\n",
       "radius          21\n",
       "Name: service, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['service'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41663b9c-9c28-4a96-b6cd-74d45c6cb93e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 257673 entries, 0 to 175340\n",
      "Data columns (total 44 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   dur                257673 non-null  float64\n",
      " 1   proto              257673 non-null  object \n",
      " 2   service            257673 non-null  object \n",
      " 3   state              257673 non-null  object \n",
      " 4   spkts              257673 non-null  int64  \n",
      " 5   dpkts              257673 non-null  int64  \n",
      " 6   sbytes             257673 non-null  int64  \n",
      " 7   dbytes             257673 non-null  int64  \n",
      " 8   rate               257673 non-null  float64\n",
      " 9   sttl               257673 non-null  int64  \n",
      " 10  dttl               257673 non-null  int64  \n",
      " 11  sload              257673 non-null  float64\n",
      " 12  dload              257673 non-null  float64\n",
      " 13  sloss              257673 non-null  int64  \n",
      " 14  dloss              257673 non-null  int64  \n",
      " 15  sinpkt             257673 non-null  float64\n",
      " 16  dinpkt             257673 non-null  float64\n",
      " 17  sjit               257673 non-null  float64\n",
      " 18  djit               257673 non-null  float64\n",
      " 19  swin               257673 non-null  int64  \n",
      " 20  stcpb              257673 non-null  int64  \n",
      " 21  dtcpb              257673 non-null  int64  \n",
      " 22  dwin               257673 non-null  int64  \n",
      " 23  tcprtt             257673 non-null  float64\n",
      " 24  synack             257673 non-null  float64\n",
      " 25  ackdat             257673 non-null  float64\n",
      " 26  smean              257673 non-null  int64  \n",
      " 27  dmean              257673 non-null  int64  \n",
      " 28  trans_depth        257673 non-null  int64  \n",
      " 29  response_body_len  257673 non-null  int64  \n",
      " 30  ct_srv_src         257673 non-null  int64  \n",
      " 31  ct_state_ttl       257673 non-null  int64  \n",
      " 32  ct_dst_ltm         257673 non-null  int64  \n",
      " 33  ct_src_dport_ltm   257673 non-null  int64  \n",
      " 34  ct_dst_sport_ltm   257673 non-null  int64  \n",
      " 35  ct_dst_src_ltm     257673 non-null  int64  \n",
      " 36  is_ftp_login       257673 non-null  int64  \n",
      " 37  ct_ftp_cmd         257673 non-null  int64  \n",
      " 38  ct_flw_http_mthd   257673 non-null  int64  \n",
      " 39  ct_src_ltm         257673 non-null  int64  \n",
      " 40  ct_srv_dst         257673 non-null  int64  \n",
      " 41  is_sm_ips_ports    257673 non-null  int64  \n",
      " 42  attack_cat         257673 non-null  object \n",
      " 43  label              257673 non-null  int64  \n",
      "dtypes: float64(11), int64(29), object(4)\n",
      "memory usage: 88.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c98827c-0d74-4b1f-86e0-08a1146bfe85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257673, 44)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b36df9f6-849a-4577-a7f6-913ebf401e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct label names and their counts:\n",
      "Normal            93000\n",
      "Generic           58871\n",
      "Exploits          44525\n",
      "Fuzzers           24246\n",
      "DoS               16353\n",
      "Reconnaissance    13987\n",
      "Analysis           2677\n",
      "Backdoor           2329\n",
      "Shellcode          1511\n",
      "Worms               174\n",
      "Name: attack_cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_counts = data['attack_cat'].value_counts()\n",
    "print(\"Distinct label names and their counts:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9a2944-4c63-4ad6-b40c-73d6d1a555a6",
   "metadata": {},
   "source": [
    "##### Encode the Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a8dcd51-f38b-449d-84f4-34756ad3204e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dur  proto  service  state  spkts  dpkts  sbytes  dbytes         rate  \\\n",
      "0  0.000011    119        0      5      2      0     496       0   90909.0902   \n",
      "1  0.000008    119        0      5      2      0    1762       0  125000.0003   \n",
      "2  0.000005    119        0      5      2      0    1068       0  200000.0051   \n",
      "3  0.000006    119        0      5      2      0     900       0  166666.6608   \n",
      "4  0.000010    119        0      5      2      0    2126       0  100000.0025   \n",
      "\n",
      "   sttl  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
      "0   254  ...                 1               2             0           0   \n",
      "1   254  ...                 1               2             0           0   \n",
      "2   254  ...                 1               3             0           0   \n",
      "3   254  ...                 1               3             0           0   \n",
      "4   254  ...                 1               3             0           0   \n",
      "\n",
      "   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
      "0                 0           1           2                0           6   \n",
      "1                 0           1           2                0           6   \n",
      "2                 0           1           3                0           6   \n",
      "3                 0           2           3                0           6   \n",
      "4                 0           2           3                0           6   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to categorical columns\n",
    "for col in ['proto', 'service', 'state', 'attack_cat']:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# Display the first few rows of the encoded DataFrame\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43b7470-e6c1-4975-a934-6226497c8f1e",
   "metadata": {},
   "source": [
    "##### Display the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f750d734-bfac-4028-a21b-3eb42794cdfe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 257673 entries, 0 to 175340\n",
      "Data columns (total 44 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   dur                257673 non-null  float64\n",
      " 1   proto              257673 non-null  int32  \n",
      " 2   service            257673 non-null  int32  \n",
      " 3   state              257673 non-null  int32  \n",
      " 4   spkts              257673 non-null  int64  \n",
      " 5   dpkts              257673 non-null  int64  \n",
      " 6   sbytes             257673 non-null  int64  \n",
      " 7   dbytes             257673 non-null  int64  \n",
      " 8   rate               257673 non-null  float64\n",
      " 9   sttl               257673 non-null  int64  \n",
      " 10  dttl               257673 non-null  int64  \n",
      " 11  sload              257673 non-null  float64\n",
      " 12  dload              257673 non-null  float64\n",
      " 13  sloss              257673 non-null  int64  \n",
      " 14  dloss              257673 non-null  int64  \n",
      " 15  sinpkt             257673 non-null  float64\n",
      " 16  dinpkt             257673 non-null  float64\n",
      " 17  sjit               257673 non-null  float64\n",
      " 18  djit               257673 non-null  float64\n",
      " 19  swin               257673 non-null  int64  \n",
      " 20  stcpb              257673 non-null  int64  \n",
      " 21  dtcpb              257673 non-null  int64  \n",
      " 22  dwin               257673 non-null  int64  \n",
      " 23  tcprtt             257673 non-null  float64\n",
      " 24  synack             257673 non-null  float64\n",
      " 25  ackdat             257673 non-null  float64\n",
      " 26  smean              257673 non-null  int64  \n",
      " 27  dmean              257673 non-null  int64  \n",
      " 28  trans_depth        257673 non-null  int64  \n",
      " 29  response_body_len  257673 non-null  int64  \n",
      " 30  ct_srv_src         257673 non-null  int64  \n",
      " 31  ct_state_ttl       257673 non-null  int64  \n",
      " 32  ct_dst_ltm         257673 non-null  int64  \n",
      " 33  ct_src_dport_ltm   257673 non-null  int64  \n",
      " 34  ct_dst_sport_ltm   257673 non-null  int64  \n",
      " 35  ct_dst_src_ltm     257673 non-null  int64  \n",
      " 36  is_ftp_login       257673 non-null  int64  \n",
      " 37  ct_ftp_cmd         257673 non-null  int64  \n",
      " 38  ct_flw_http_mthd   257673 non-null  int64  \n",
      " 39  ct_src_ltm         257673 non-null  int64  \n",
      " 40  ct_srv_dst         257673 non-null  int64  \n",
      " 41  is_sm_ips_ports    257673 non-null  int64  \n",
      " 42  attack_cat         257673 non-null  int32  \n",
      " 43  label              257673 non-null  int64  \n",
      "dtypes: float64(11), int32(4), int64(29)\n",
      "memory usage: 84.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03997e40-a394-4f1d-a335-1cdb1d94b174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257673, 44)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818ae7d-7e56-4073-8a69-fe2fc7a1d305",
   "metadata": {},
   "source": [
    "##### Check if there is any NaN in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa4c58ef-2ff5-46b6-be78-7c9855fcca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0901419b-8a22-41e0-8f24-7913b0206a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257673, 44)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9710a04-a5dd-42cb-847c-a37fde00df5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>90909.0902</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1762</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.0003</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1068</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0051</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>166666.6608</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2126</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0025</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur  proto  service  state  spkts  dpkts  sbytes  dbytes         rate  \\\n",
       "0  0.000011    119        0      5      2      0     496       0   90909.0902   \n",
       "1  0.000008    119        0      5      2      0    1762       0  125000.0003   \n",
       "2  0.000005    119        0      5      2      0    1068       0  200000.0051   \n",
       "3  0.000006    119        0      5      2      0     900       0  166666.6608   \n",
       "4  0.000010    119        0      5      2      0    2126       0  100000.0025   \n",
       "\n",
       "   sttl  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
       "0   254  ...                 1               2             0           0   \n",
       "1   254  ...                 1               2             0           0   \n",
       "2   254  ...                 1               3             0           0   \n",
       "3   254  ...                 1               3             0           0   \n",
       "4   254  ...                 1               3             0           0   \n",
       "\n",
       "   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
       "0                 0           1           2                0           6   \n",
       "1                 0           1           2                0           6   \n",
       "2                 0           1           3                0           6   \n",
       "3                 0           2           3                0           6   \n",
       "4                 0           2           3                0           6   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77ac4fcc-042a-442a-b9b8-72cc1d9d3a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct label names and their counts:\n",
      "6    93000\n",
      "5    58871\n",
      "3    44525\n",
      "4    24246\n",
      "2    16353\n",
      "7    13987\n",
      "0     2677\n",
      "1     2329\n",
      "8     1511\n",
      "9      174\n",
      "Name: attack_cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_counts = data['attack_cat'].value_counts()\n",
    "print(\"Distinct label names and their counts:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b73b91-9e97-489c-878a-9cdd55272676",
   "metadata": {},
   "source": [
    "##### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "299156fc-452b-444e-b79a-3da8291b8bb9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized DataFrame using Min-Max Scaling:\n",
      "                 dur     proto   service  state     spkts     dpkts    sbytes  \\\n",
      "0       1.833334e-07  0.901515  0.000000    0.5  0.000094  0.000000  0.000033   \n",
      "1       1.333334e-07  0.901515  0.000000    0.5  0.000094  0.000000  0.000121   \n",
      "2       8.333335e-08  0.901515  0.000000    0.5  0.000094  0.000000  0.000073   \n",
      "3       1.000000e-07  0.901515  0.000000    0.5  0.000094  0.000000  0.000061   \n",
      "4       1.666667e-07  0.901515  0.000000    0.5  0.000094  0.000000  0.000146   \n",
      "...              ...       ...       ...    ...       ...       ...       ...   \n",
      "257668  1.500000e-07  0.901515  0.166667    0.5  0.000094  0.000000  0.000006   \n",
      "257669  8.429368e-03  0.856061  0.000000    0.4  0.000845  0.000726  0.000042   \n",
      "257670  1.500000e-07  0.901515  0.166667    0.5  0.000094  0.000000  0.000006   \n",
      "257671  1.500000e-07  0.901515  0.166667    0.5  0.000094  0.000000  0.000006   \n",
      "257672  1.500000e-07  0.901515  0.166667    0.5  0.000094  0.000000  0.000006   \n",
      "\n",
      "          dbytes      rate      sttl  ...  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
      "0       0.000000  0.090909  0.996078  ...          0.000000        0.015625   \n",
      "1       0.000000  0.125000  0.996078  ...          0.000000        0.015625   \n",
      "2       0.000000  0.200000  0.996078  ...          0.000000        0.031250   \n",
      "3       0.000000  0.166667  0.996078  ...          0.000000        0.031250   \n",
      "4       0.000000  0.100000  0.996078  ...          0.000000        0.031250   \n",
      "...          ...       ...       ...  ...               ...             ...   \n",
      "257668  0.000000  0.111111  0.996078  ...          0.266667        0.359375   \n",
      "257669  0.000024  0.000034  0.996078  ...          0.000000        0.015625   \n",
      "257670  0.000000  0.111111  0.996078  ...          0.044444        0.187500   \n",
      "257671  0.000000  0.111111  0.996078  ...          0.288889        0.453125   \n",
      "257672  0.000000  0.111111  0.996078  ...          0.333333        0.453125   \n",
      "\n",
      "        is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
      "0                0.0         0.0               0.0    0.000000    0.016393   \n",
      "1                0.0         0.0               0.0    0.000000    0.016393   \n",
      "2                0.0         0.0               0.0    0.000000    0.032787   \n",
      "3                0.0         0.0               0.0    0.016949    0.032787   \n",
      "4                0.0         0.0               0.0    0.016949    0.032787   \n",
      "...              ...         ...               ...         ...         ...   \n",
      "257668           0.0         0.0               0.0    0.389831    0.377049   \n",
      "257669           0.0         0.0               0.0    0.000000    0.000000   \n",
      "257670           0.0         0.0               0.0    0.033898    0.180328   \n",
      "257671           0.0         0.0               0.0    0.491525    0.475410   \n",
      "257672           0.0         0.0               0.0    0.491525    0.475410   \n",
      "\n",
      "        is_sm_ips_ports  attack_cat  label  \n",
      "0                   0.0    0.666667    0.0  \n",
      "1                   0.0    0.666667    0.0  \n",
      "2                   0.0    0.666667    0.0  \n",
      "3                   0.0    0.666667    0.0  \n",
      "4                   0.0    0.666667    0.0  \n",
      "...                 ...         ...    ...  \n",
      "257668              0.0    0.555556    1.0  \n",
      "257669              0.0    0.888889    1.0  \n",
      "257670              0.0    0.555556    1.0  \n",
      "257671              0.0    0.555556    1.0  \n",
      "257672              0.0    0.555556    1.0  \n",
      "\n",
      "[257673 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the dataframe\n",
    "normalized_df = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "\n",
    "print(\"Normalized DataFrame using Min-Max Scaling:\")\n",
    "print(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f275dac8-00e5-44c8-8050-325750e08af7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct label names and their counts:\n",
      "0.666667    93000\n",
      "0.555556    58871\n",
      "0.333333    44525\n",
      "0.444444    24246\n",
      "0.222222    16353\n",
      "0.777778    13987\n",
      "0.000000     2677\n",
      "0.111111     2329\n",
      "0.888889     1511\n",
      "1.000000      174\n",
      "Name: attack_cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_counts = normalized_df['attack_cat'].value_counts()\n",
    "print(\"Distinct label names and their counts:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec24a8ac-0105-448e-ae1a-685b0b0d313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows with specified labels\n",
    "selected_labels = [1.000000]\n",
    "\n",
    "# Check the precision of the labels in the DataFrame\n",
    "\n",
    "selected_rows = normalized_df[normalized_df['attack_cat'].isin(selected_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ca7a24f-2117-4109-a29e-8d9f5e1ab4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174, 44)\n"
     ]
    }
   ],
   "source": [
    "print(selected_rows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04a5d28d-adbc-4ee0-a0f1-8a6e23717519",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = selected_rows.iloc[:, :-1].values  # Features (excluding the label column)\n",
    "y = selected_rows.iloc[:, -1].values   # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3415b368-9a4f-42b0-a3cc-d86bb0c46cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cea20bc4-0512-45b7-815b-fe86b5a93a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5018b89c-98d2-4a3c-bbd6-1b3e44775b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "\n",
    "# Define WGAN-GP components\n",
    "def make_generator_model(input_dim, output_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(128, use_bias=False, input_shape=(input_dim,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(256, use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(output_dim, activation='tanh'))\n",
    "    return model\n",
    "\n",
    "def make_discriminator_model(input_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, input_shape=(input_dim,)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(128))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = tf.reduce_mean(real_output)\n",
    "    fake_loss = tf.reduce_mean(fake_output)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return -tf.reduce_mean(fake_output)\n",
    "\n",
    "def gradient_penalty(discriminator, real_data, fake_data):\n",
    "    batch_size = real_data.shape[0]\n",
    "    alpha = tf.random.uniform([batch_size, 1], 0.0, 1.0)\n",
    "    real_data = tf.cast(real_data, tf.float32)\n",
    "    fake_data = tf.cast(fake_data, tf.float32)\n",
    "    diff = fake_data - real_data\n",
    "    interpolated = real_data + alpha * diff\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        pred = discriminator(interpolated)\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=1))\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return gp\n",
    "\n",
    "@tf.function\n",
    "def train_step(real_data, generator, discriminator, generator_optimizer, discriminator_optimizer, batch_size, z_dim, gp_weight):\n",
    "    noise = tf.random.normal([batch_size, z_dim])\n",
    "    real_data = tf.cast(real_data, tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        fake_data = generator(noise, training=True)\n",
    "        real_output = discriminator(real_data, training=True)\n",
    "        fake_output = discriminator(fake_data, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        gp = gradient_penalty(discriminator, real_data, fake_data)\n",
    "        total_disc_loss = disc_loss + gp * gp_weight\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(total_disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "# WGAN-GP training function\n",
    "def train_wgan_gp(X, epochs, batch_size, z_dim, gp_weight, generator, discriminator, generator_optimizer, discriminator_optimizer):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(tf.cast(X, tf.float32)).shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for real_data in dataset:\n",
    "            if real_data.shape[0] != batch_size:\n",
    "                continue  # Skip the batch if it does not match the required batch size\n",
    "            train_step(real_data, generator, discriminator, generator_optimizer, discriminator_optimizer, batch_size, z_dim, gp_weight)\n",
    "\n",
    "    noise = tf.random.normal([X.shape[0], z_dim])\n",
    "    synthetic_data = generator(noise, training=False)\n",
    "    return synthetic_data\n",
    "\n",
    "# Set WGAN-GP parameters\n",
    "z_dim = 10\n",
    "gp_weight = 10.0\n",
    "batch_size = 1\n",
    "epochs = 20  # Adjust as needed\n",
    "\n",
    "# Create WGAN-GP models and optimizers\n",
    "generator = make_generator_model(z_dim, X.shape[1])\n",
    "discriminator = make_discriminator_model(X.shape[1])\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# Train WGAN-GP and generate synthetic data\n",
    "synthetic_X = train_wgan_gp(X, epochs, batch_size, z_dim, gp_weight, generator, discriminator, generator_optimizer, discriminator_optimizer)\n",
    "synthetic_y = np.random.choice(y, size=synthetic_X.shape[0])  # Assuming same distribution for labels\n",
    "\n",
    "# Combine real and synthetic data\n",
    "X_combined = np.vstack((X, synthetic_X))\n",
    "y_combined = np.hstack((y, synthetic_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4f7bef3-98a4-4665-8471-f04b580344bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2784, 43)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88cebd96-751a-41bd-a26d-7c44c0e6617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into a single DataFrame\n",
    "df_combined = pd.DataFrame(X_combined)\n",
    "df_combined['Label'] = y_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6d0be2e7-c111-42b2-a9e9-31ec747ad476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.columns=normalized_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6afa39c0-df3d-463e-aaa0-242e9569be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = normalized_df[normalized_df['attack_cat'] != 1.000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "403e285c-d47f-4f78-8914-1be4669c8083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257499, 44)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "473d90f6-bbd0-4c6c-bc1b-347a508dfa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=pd.concat([df_filtered,df_combined],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "00ac1b7f-ae66-4022-92fe-d48153481f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260283, 44)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2d3e4a74-6be1-414b-9b83-ceccb6e05495",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new.iloc[:, :-1].values  # Features (excluding the label column)\n",
    "y = df_new.iloc[:, -1].values   # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7f181fed-7add-49b7-9820-c46e59617b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indian Millipede Optimization Algorithm(IMOA) based feature selection\n",
    "# Define the fitness function for feature selection based on mutual information\n",
    "def fitness_function(mask):\n",
    "    selected_features = np.where(mask == 1)[0]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # No features selected, so fitness is zero\n",
    "    \n",
    "    X_selected = X_combined[:, selected_features]\n",
    "    mi = mutual_info_classif(X_selected, y_combined, discrete_features='auto')\n",
    "    return np.sum(mi)  # Maximize the sum of mutual information of selected features\n",
    "\n",
    "# Define the constraint violation function (if any)\n",
    "def constraint_violation(mask):\n",
    "    return 0  # No constraints in this case\n",
    "\n",
    "# Initialize parameters\n",
    "N = 20  # Population size\n",
    "d = X.shape[1]  # Dimensionality of the problem (number of features)\n",
    "T = 100  # Maximum iterations\n",
    "T_th = 0.5  # Temperature threshold\n",
    "α = 0.1  # Seasonal activity factor\n",
    "β = 0.5  # Reversal factor\n",
    "γ = 0.1  # Learning rate\n",
    "δ = 0.01  # Step size\n",
    "ε = 0.1  # Social factor\n",
    "λ = 10  # Penalty coefficient\n",
    "η = 0.5  # Crossover coefficient\n",
    "convergence_threshold = 1e-6  # Convergence threshold for fitness improvement\n",
    "no_improvement_limit = 10  # Number of iterations to wait for improvement before stopping\n",
    "\n",
    "# Initialize population\n",
    "P = np.random.randint(0, 2, (N, d))  # Binary mask for feature selection\n",
    "\n",
    "# Evaluate initial fitness\n",
    "fitness = np.array([fitness_function(mask) for mask in P])\n",
    "penalized_fitness = fitness - λ * np.array([constraint_violation(mask) for mask in P])\n",
    "\n",
    "# Main IMOA loop\n",
    "t = 0\n",
    "no_improvement_count = 0\n",
    "best_fitness = np.max(penalized_fitness)\n",
    "best_solution = P[np.argmax(penalized_fitness)]\n",
    "\n",
    "while t < T and no_improvement_count < no_improvement_limit:\n",
    "    for i in range(N):\n",
    "        # Seasonal Abundance\n",
    "        α_t = α * np.sin(2 * np.pi * t / T)\n",
    "        P[i] = np.clip(P[i] + α_t * np.random.uniform(-1, 1, d), 0, 1).astype(int)\n",
    "        \n",
    "        # Obstacle Avoidance\n",
    "        if penalized_fitness[i] < np.mean(penalized_fitness):  # Assuming poor fitness as below mean fitness\n",
    "            P[i] = np.clip(P[i] - β * np.random.uniform(-1, 1, d), 0, 1).astype(int)\n",
    "        \n",
    "        # Temperature Response\n",
    "        if np.random.uniform(0, 1) > T_th:\n",
    "            best_idx = np.argmax(penalized_fitness)\n",
    "            P[i] = np.clip(P[i] + γ * (P[best_idx] - P[i]), 0, 1).astype(int)\n",
    "        \n",
    "        # Resource Utilization\n",
    "        gradient = (fitness_function(P[i] + δ) - fitness_function(P[i])) / δ\n",
    "        P[i] = np.clip(P[i] + δ * gradient, 0, 1).astype(int)\n",
    "        \n",
    "        # Group Movement\n",
    "        P[i] = np.clip(P[i] + ε * (np.mean(P, axis=0) - P[i]), 0, 1).astype(int)\n",
    "        \n",
    "        # Defensive Behavior\n",
    "        if penalized_fitness[i] < np.mean(penalized_fitness):  # Assuming poor fitness as below mean fitness\n",
    "            penalized_fitness[i] -= λ * constraint_violation(P[i])\n",
    "        \n",
    "        # Mating Behavior\n",
    "        mate_idx = np.random.randint(N)\n",
    "        P[i] = np.clip(η * P[i] + (1 - η) * P[mate_idx], 0, 1).astype(int)\n",
    "        \n",
    "        # Predator Avoidance\n",
    "        if np.std(P) < 1e-6:  # Assuming low diversity as low standard deviation\n",
    "            P[i] = np.random.randint(0, 2, d)\n",
    "    \n",
    "    # Evaluate fitness of new positions\n",
    "    fitness = np.array([fitness_function(mask) for mask in P])\n",
    "    penalized_fitness = fitness - λ * np.array([constraint_violation(mask) for mask in P])\n",
    "    \n",
    "    # Check for convergence\n",
    "    current_best_fitness = np.max(penalized_fitness)\n",
    "    if current_best_fitness > best_fitness + convergence_threshold:\n",
    "        best_fitness = current_best_fitness\n",
    "        best_solution = P[np.argmax(penalized_fitness)]\n",
    "        no_improvement_count = 0\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "    \n",
    "    # Increment iteration counter\n",
    "    t += 1\n",
    "selected_features = np.where(best_solution == 1 )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6ca8f3d7-0774-4360-baf5-e3d17835e350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: [ 0  1  2  3  6  7 12 13 15 17 19 20 21 22 24 25 27 28 31 35 37 39]\n"
     ]
    }
   ],
   "source": [
    "# Print the selected features\n",
    "\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f4f90642-b0a5-44a0-9aaa-592201014225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_entries = len( selected_features)\n",
    "num_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4cecf35a-9f99-480f-a796-74d68612f83c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dur\n",
      "proto\n",
      "service\n",
      "state\n",
      "sbytes\n",
      "dbytes\n",
      "dload\n",
      "sloss\n",
      "sinpkt\n",
      "sjit\n",
      "swin\n",
      "stcpb\n",
      "dtcpb\n",
      "dwin\n",
      "synack\n",
      "ackdat\n",
      "dmean\n",
      "trans_depth\n",
      "ct_state_ttl\n",
      "ct_dst_src_ltm\n",
      "ct_ftp_cmd\n",
      "ct_src_ltm\n"
     ]
    }
   ],
   "source": [
    "for feature_index in selected_features:\n",
    "    print(data.columns[feature_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a234ae4e-fff6-4a27-89d6-e4c3478c496e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to UNSW_merged_filtered_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the filename\n",
    "filename = 'UNSW_merged_filtered_data.csv'\n",
    "filename1 = 'UNSW_augmented_filtered_data.csv'\n",
    "filename2='UNSW_filtered_data.csv'\n",
    "# Save the DataFrame to a CSV file\n",
    "df_new.to_csv(filename, index=False)\n",
    "normalized_df.to_csv(filename1, index=False)\n",
    "df_combined.to_csv(filename2, index=False)\n",
    "print(f\"DataFrame saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd13eded-ffd4-4d3a-bddc-ee54a694095e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
